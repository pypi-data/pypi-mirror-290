Metadata-Version: 2.1
Name: nexaai-gpu
Version: 0.0.1.dev0
Summary: Nexa AI SDK
Home-page: https://github.com/NexaAI/nexa-sdk
Author: Nexa AI
Author-email: octopus@nexa4ai.com
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: typing-extensions >=4.5.0
Requires-Dist: numpy >=1.20.0
Requires-Dist: diskcache >=5.6.1
Requires-Dist: jinja2 >=2.11.3
Requires-Dist: boto3 >=1.34.148
Requires-Dist: botocore >=1.34.148
Requires-Dist: fastapi
Requires-Dist: uvicorn
Requires-Dist: sse-starlette
Requires-Dist: pydantic-settings
Requires-Dist: diskcache
Requires-Dist: starlette-context
Requires-Dist: pillow
Requires-Dist: streamlit
Requires-Dist: tqdm
Requires-Dist: tabulate
Requires-Dist: pydantic
Requires-Dist: PyYAML
Requires-Dist: requests
Requires-Dist: setuptools >=42
Requires-Dist: prompt-toolkit
Requires-Dist: stable-diffusion-cpp-python ==0.1.6
Provides-Extra: onnx
Requires-Dist: librosa ; extra == 'onnx'
Requires-Dist: optimum[onnxruntime] >=1.7.3 ; extra == 'onnx'
Requires-Dist: diffusers ; extra == 'onnx'
Requires-Dist: optuna ; extra == 'onnx'
Requires-Dist: soundfile ; extra == 'onnx'
Requires-Dist: streamlit-audiorec ; extra == 'onnx'
Requires-Dist: transformers ; extra == 'onnx'
Requires-Dist: ttstokenizer ; extra == 'onnx'

# Nexa SDK

The Nexa SDK is a comprehensive toolkit for supporting **ONNX** and **GGML** models. It supports text generation, image generation, vision-language models (VLM), and text-to-speech (TTS) capabilities. Additionally, it offers an OpenAI-compatible API server with JSON schema mode for function calling and streaming support, and a user-friendly Streamlit UI.

## Features
- **Model Support:**
  - **ONNX & GGML models**
  - **Conversion Engine**
  - **Inference Engine**:
    - **Text Generation**
    - **Image Generation**
    - **Vision-Language Models (VLM)**
    - **Text-to-Speech (TTS)**
- **Server:**
  - OpenAI-compatible API
  - JSON schema mode for function calling
  - Streaming support
- **Streamlit UI** for interactive model deployment and testing

## Installation
For CPU version
```
pip install nexaai
pip install nexaai[onnx] # if you want to use ONNX models
```
For GPU version
```
pip install nexaai-gpu
pip install nexaai-gpu[onnx] # if you want to use ONNX models
```

## Nexa CLI commands
## Model Commands

### NLP Models

| Model        | Type   | Format        | Command                          |
|--------------|--------|---------------|----------------------------------|
| octopus-v2   | NLP    | GGUF          | `nexa-cli gen-text octopus-v2`   |
| octopus-v4   | NLP    | GGUF          | `nexa-cli gen-text octopus-v4`   |
| tinyllama    | NLP    | GGUF          | `nexa-cli gen-text tinyllama`    |
| llama2       | NLP    | GGUF/ONNX     | `nexa-cli gen-text llama2`       |
| llama3       | NLP    | GGUF/ONNX     | `nexa-cli gen-text llama3`       |
| llama3.1     | NLP    | GGUF/ONNX     | `nexa-cli gen-text llama3.1`     |
| gemma        | NLP    | GGUF/ONNX     | `nexa-cli gen-text gemma`        |
| gemma2       | NLP    | GGUF          | `nexa-cli gen-text gemma2`       |
| qwen1.5      | NLP    | GGUF          | `nexa-cli gen-text qwen1.5`      |
| qwen2        | NLP    | GGUF/ONNX     | `nexa-cli gen-text qwen2`        |
| mistral      | NLP    | GGUF/ONNX     | `nexa-cli gen-text mistral`      |
| codegemma    | NLP    | GGUF          | `nexa-cli gen-text codegemma`    |
| codellama    | NLP    | GGUF          | `nexa-cli gen-text codellama`    |
| codeqwen     | NLP    | GGUF          | `nexa-cli gen-text codeqwen`     |
| deepseek-coder | NLP  | GGUF          | `nexa-cli gen-text deepseek-coder` |
| dolphin-mistral | NLP | GGUF          | `nexa-cli gen-text dolphin-mistral` |
| nomic-embed-text | NLP | GGUF         | `nexa-cli gen-text nomic-embed-text` |
| phi2         | NLP    | GGUF          | `nexa-cli gen-text phi2`         |
| phi3         | NLP    | GGUF/ONNX     | `nexa-cli gen-text phi3`         |

### Multimodal Models

| Model            | Type        | Format        | Command                         |
|------------------|-------------|---------------|---------------------------------|
| nanollava        | Multimodal  | GGUF          | `nexa-cli vlm nanollava`        |
| llava-phi3       | Multimodal  | GGUF          | `nexa-cli vlm llava-phi3`       |
| llava-llama3     | Multimodal  | GGUF          | `nexa-cli vlm llava-llama3`     |
| llava1.6-mistral | Multimodal  | GGUF          | `nexa-cli vlm llava1.6-mistral` |
| llava1.6-vicuna  | Multimodal  | GGUF          | `nexa-cli vlm llava1.6-vicuna`  |

### Computer Vision Models

| Model                | Type             | Format        | Command                             |
|----------------------|------------------|---------------|-------------------------------------|
| stable-diffusion-v1-4 | Computer Vision | GGUF          | `nexa-cli gen-image sd1-4`          |
| stable-diffusion-v1-5 | Computer Vision | GGUF/ONNX     | `nexa-cli gen-image sd1-5`          |
| lcm-dreamshaper       | Computer Vision | GGUF/ONNX     | `nexa-cli gen-image lcm-dreamshaper` |
