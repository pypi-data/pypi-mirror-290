import osimport reimport tempfileimport tracebackfrom itertools import productimport geopandas as gpdfrom typing import Unionimport numpy as npimport pandas as pdimport pyprojimport rasterioimport shapelyfrom affine import Affinefrom boto3 import Sessionfrom rasterio import DatasetReader, MemoryFile, windowsfrom rasterio.coords import BoundingBoxfrom rasterio.crs import CRSfrom rasterio.enums import Resamplingfrom rasterio.features import shapes, rasterizefrom rasterio.mask import maskfrom rasterio.plot import showfrom rasterio.session import AWSSessionfrom rasterio.shutil import copyfrom rasterio.warp import calculate_default_transform, reprojectfrom shapely.geometry import shape, Polygonfrom digitalarztools.proccessing.operations.geodesy import GeodesyOpsfrom digitalarztools.io.file_io import FileIOfrom digitalarztools.io.raster.band_process import BandProcessfrom digitalarztools.io.raster.indices import IndicesCalcfrom digitalarztools.utils.logger import da_loggerfrom digitalarztools.io.vector.gpd_vector import GPDVectorclass RioRaster:    """    Geo Raster class containing information about geotransform and projection.    GDAL geotransform = (c,a,b, f,d,e)    RasterIO = (a,b,c,d,e,f)    """    dataset: DatasetReader = None    parent_img_name: str = None    temp_dir: str = None    resampling_method: list = [Resampling.nearest, Resampling.bilinear, Resampling.cubic, Resampling.lanczos,                               Resampling.average, Resampling.cubic_spline]    def __init__(self, src: Union[str, DatasetReader, None], prj_path: str = None, s3_session=None):        if src is not None:            self.set_dataset(src, s3_session)            if prj_path is not None and os.path.exists(prj_path):                self.add_crs_from_prj(prj_path)        else:            self.dataset = None    # def __del__(self):    #     self.dataset.close()    #     del self.dataset    @property    def empty(self):        return self.dataset is None    def set_temp_folder(self, temp_dir: str):        self.temp_dir = temp_dir    def plot_data(self, band_nu: int = -1):        """        Plot the raster data.        :param band_nu: The band number to plot. If -1, plots the entire dataset.        """        if band_nu == -1:            show(self.dataset)        else:            show(self.dataset.read(1), transform=self.get_geo_transform())    def set_dataset(self, src: Union[str, DatasetReader], s3_session=None):        """        Set the raster dataset from a source.        :param src: The source path or DatasetReader object.        :param s3_session: The AWS session for S3 access, if required.        """        try:            if isinstance(src, DatasetReader):                if '/vsipythonfilelike/' in src.name:                    self.dataset = self.rio_dataset_from_array(src.read(), src.meta)                else:                    self.dataset = src            elif isinstance(src, str):                if "s3://" in src:                    session = rasterio.Env(AWSSession(s3_session))                    with session:                        self.dataset = rasterio.open(src)                elif "/vsimem/" in src:                    with MemoryFile(src) as memfile:                        self.dataset = memfile.open()                else:                    if os.path.exists(src):                        self.dataset = rasterio.open(src, mode='r+', ignore_cog_layout_break='YES')                    else:                        raise FileNotFoundError(f"Raster file not available at {src}")            if self.dataset is None:                raise ValueError("Dataset could not be set. It is None.")        except Exception as e:            da_logger.error(f"Error setting dataset: {e}")            traceback.print_exc()    def get_dataset(self) -> DatasetReader:        """Get the current dataset."""        return self.dataset    def get_meta(self):        """Get the metadata of the current dataset."""        return self.dataset.meta    def get_metadata_copy(self):        """Get a copy of the dataset metadata."""        return self.dataset.meta.copy()    def update_metadata(self, metadata):        """        Update the metadata of the dataset.        :param metadata: The new metadata to apply.        """        memfile = MemoryFile()        dst = memfile.open(**metadata)        dst.write(self.dataset.read())        dst.close()        self.dataset = memfile.open()    def get_dtype(self):        """Get the data type of the dataset."""        return self.dataset.meta['dtype']    def get_nodata_value(self):        """Get the no-data value of the dataset."""        return self.dataset.meta['nodata']    def get_nodata_value_of_band(self, band_number):        """        Get the no-data value for a specific band.        :param band_number: The band number.        """        return self.dataset.nodatavals[band_number - 1]    def get_overviews(self, num):        """Get the overviews of the dataset."""        return self.dataset.overviews(num)  # list of overviews from biggest to smallest    def get_profile(self):        """Get the profile of the dataset."""        return self.dataset.profile    def get_file_name(self) -> (str, str):        """        Get the file name and directory of the dataset.        :return: Tuple of directory name and base file name.        """        if self.dataset.files and len(self.dataset.files) > 0:            file_name = str(self.dataset.files[0])            dir_name = os.path.dirname(file_name)            base_name = os.path.basename(file_name)            return dir_name, base_name    @classmethod    def separate_file_path_name(cls, file_path_name: str):        """        Separate the file path and name.        :param file_path_name: The full file path.        :return: Tuple of directory and file name.        """        file_dir = os.path.dirname(file_path_name)        file_name = os.path.basename(file_path_name)        return file_dir, file_name    @classmethod    def get_file_name_extension(cls, file_name: str) -> (str, str):        """        Get the file name and extension.        :param file_name: The file name.        :return: Tuple of file name and extension.        """        split = file_name.split(".")        if len(split) == 2:            return split[0], split[1]        return file_name, None    def get_file_extension(self):        """        Get the file extension of the dataset.        :return: The file extension.        """        try:            _, name = self.separate_file_path_name(self.get_file_name())            _, ext = self.get_file_name_extension(name)            return ext        except Exception as e:            da_logger.error(f"Error getting file extension: {e}")            traceback.print_exc()    def get_bounds(self) -> BoundingBox:        """Get the bounds of the dataset."""        return self.dataset.bounds    def get_extent_after_skip_rows_cols(self, n_rows_skip, n_cols_skip):        """        Get the extent of the dataset after skipping rows and columns.        :param n_rows_skip: Number of rows to skip.        :param n_cols_skip: Number of columns to skip.        :return: The new extent.        """        y_size, x_size = self.get_img_resolution()        geo_t = self.get_geo_transform()        min_x = geo_t[2] + n_cols_skip * geo_t[0]        max_y = geo_t[5] + n_rows_skip * geo_t[4]        max_x = geo_t[2] + geo_t[0] * (x_size - n_cols_skip)        min_y = geo_t[5] + geo_t[4] * (y_size - n_rows_skip)        return (min_x, min_y, max_x, max_y)    def get_envelop(self, n_rows_skp=0, n_cols_skip=0, srid=0) -> gpd.GeoDataFrame:        """        Get the envelope of the dataset.        :param n_rows_skp: Number of rows to skip.        :param n_cols_skip: Number of columns to skip.        :param srid: The spatial reference ID.        :return: The envelope as a GeoDataFrame.        """        if n_rows_skp != 0 or n_cols_skip != 0:            extent = self.get_extent_after_skip_rows_cols(n_rows_skp, n_cols_skip)        else:            extent = self.get_raster_extent()        envelop = GPDVector.extent_2_envelop(*extent, crs=self.get_crs())        if srid != 0:            envelop.to_crs(epsg=srid)        return envelop.get_gdf()    def get_raster_extent(self) -> list:        """Get the extent of the raster."""        bounds = self.dataset.bounds        return [bounds.left, bounds.bottom, bounds.right, bounds.top]    def get_raster_srid(self) -> int:        """        Get the spatial reference ID (SRID) of the raster.        :return: The SRID.        """        try:            profile = self.get_profile()            wkt = str(profile['crs'])            if ':' in wkt:                return int(str(profile['crs']).split(":")[-1])            else:                crs = pyproj.CRS.from_wkt(wkt)                return crs.to_epsg()        except Exception as e:            da_logger.error(f"Error getting SRID: {e}")            traceback.print_exc()            return 0    def set_crs(self, crs: pyproj.CRS):        """        Set the CRS of the dataset.        :param crs: The CRS to set.        """        crs = rasterio.crs.CRS.from_wkt(crs.to_wkt())        self.dataset.crs = crs    def get_width(self):        """Get the width of the dataset."""        return self.dataset.width    def get_height(self):        """Get the height of the dataset."""        return self.dataset.height    def get_crs(self) -> pyproj.CRS:        """Get the CRS of the dataset."""        return self.dataset.crs    def get_pyproj_crs(self) -> pyproj.CRS:        """Get the pyproj CRS of the dataset."""        try:            return pyproj.CRS.from_wkt(self.dataset.crs.to_wkt())        except Exception as e:            da_logger.error(f"Error getting pyproj CRS: {e}")            traceback.print_exc()            return pyproj.CRS.from_epsg(0)    def get_data_shape(self):        """        Get the shape of the data array.        :return: Tuple of (band, row, column).        """        data = self.get_data_array()        if len(data.shape) == 2:            band = 1            row, column = data.shape        elif len(data.shape) == 3:            band, row, column = data.shape        return band, row, column    def get_data_array(self, band=None, convert_no_data_2_nan=False,                       envelop_gdf: gpd.GeoDataFrame = None) -> np.ndarray:        """        Get the data array from the dataset.        :param band: The band number to read.        :param convert_no_data_2_nan: Whether to convert no-data values to NaN.        :param envelop_gdf: An optional envelope to restrict the data.        :return: The data array.        """        if self.dataset is not None:            dataset = self.dataset if envelop_gdf is None else self.get_dataset_under_envelop(des_gdf=envelop_gdf,                                                                                              in_place=False)            if band:                data_arr = dataset.read(band)            else:                data_arr = dataset.read()            if convert_no_data_2_nan:                data_arr = data_arr.astype(np.float)                data_arr[data_arr == self.dataset.nodata] = np.nan            return data_arr        else:            raise ValueError("raster dataset is empty")    def save_to_file(self, img_des: str, data: np.ndarray = None, crs: CRS = None,                     affine_transform: Affine = None, nodata_value=None):        """        Save the dataset to a file.        :param img_des: The destination file path.        :param data: The data array to save.        :param crs: The CRS to use.        :param affine_transform: The affine transform to use.        :param nodata_value: The no-data value to use.        """        data = self.get_data_array() if data is None else data        crs = crs if crs else self.dataset.crs        affine_transform = affine_transform if affine_transform else self.dataset.transform        nodata_value = nodata_value if nodata_value else self.get_nodata_value()        self.write_to_file(img_des, data, crs, affine_transform, nodata_value)    @staticmethod    def write_to_file(img_des: str, data: np.ndarray, crs: CRS, affine_transform: Affine, nodata_value,                      session: Session = None):        """Write raster data to a file (GeoTIFF or COG) with optional S3 support.        Args:            img_des (str): The destination file path (local or S3 URI).            data (np.ndarray): The raster data array.            crs (CRS): The Coordinate Reference System.            affine_transform (Affine): The affine transformation.            nodata_value: The no-data value.            session (Session, optional): AWS session for S3 operations. Defaults to None.        """        try:            # Create directory if local file            if not img_des.startswith("s3://"):                FileIO.mkdirs(img_des)            # Determine driver and BigTIFF            driver = 'COG' if img_des.lower().endswith('.cog') else 'GTiff'            bigtiff = 'YES' if data.nbytes > 4 * 1024 * 1024 * 1024 else 'NO'            # Get dimensions and bands            if len(data.shape) == 2:                bands, rows, cols = 1, *data.shape            else:                bands, rows, cols = data.shape            # Write raster data with optional S3 environment            with rasterio.Env(                    GDAL_TIFF_INTERNAL_MASK=True,  # Embed mask for COG                    session=AWSSession(session) if session else None  # S3 session if provided            ):                with rasterio.open(img_des, 'w', driver=driver, height=rows, width=cols,                                   count=bands, dtype=str(data.dtype), crs=crs,                                   transform=affine_transform, compress='deflate',                                   predictor=1, zlevel=9,  # Predictor and compression level for Deflate                                   nodata=nodata_value, BIGTIFF=bigtiff) as dst:                    for i in range(bands):                        d = data if bands == 1 else data[i]                        dst.write(d)                    # Add overviews for COGs (if applicable)                    if driver == 'COG':                        dst.build_overviews([2, 4, 8, 16, 32])        except rasterio.RasterioIOError as e:            print(f"Error writing raster to file {img_des}: {e}")            traceback.print_exc()    def rio_raster_from_array(self, img_arr: np.ndarray) -> 'RioRaster':        """        Create a RioRaster object from an array.        :param img_arr: The image array.        :return: A new RioRaster object.        """        meta_data = self.get_metadata_copy()        raster = self.raster_from_array(img_arr, crs=self.get_crs(),                                        g_transform=self.get_geo_transform(),                                        nodata_value=self.get_nodata_value())        return raster    @staticmethod    def raster_from_array(img_arr: np.ndarray, crs: Union[str, CRS],                          g_transform: Affine, nodata_value=None) -> 'RioRaster':        """        Create a RioRaster object from an array.        :param img_arr: The image array.        :param crs: The CRS to use.        :param g_transform: The affine transform to use.        :param nodata_value: The no-data value to use.        :return: A new RioRaster object.        """        try:            memfile = MemoryFile()            if len(img_arr.shape) == 2:                bands = 1                rows, cols = img_arr.shape            else:                bands, rows, cols = img_arr.shape            with memfile.open(driver='GTiff',                              height=rows,                              width=cols,                              count=bands,                              dtype=str(img_arr.dtype),                              crs=crs,                              transform=g_transform,                              nodata=nodata_value,                              compress='lzw',                              BIGTIFF='YES') as dataset:                for i in range(bands):                    d = img_arr if len(img_arr.shape) == 2 else img_arr[i, :, :]                    dataset.write(d, i + 1)                dataset.close()            dataset = memfile.open()  # Reopen as DatasetReader            new_raster = RioRaster(dataset)            return new_raster        except Exception as e:            print(f"Error creating raster from array: {e}")            traceback.print_exc()            return None    def add_crs_from_prj(self, prj_file):        """        Add CRS from a .prj file.        :param prj_file: The path to the .prj file.        """        crs = FileIO.read_prj_file(prj_file)        self.dataset.crs = CRS.from_wkt(crs.to_wkt())    def get_driver(self):        """Get the driver of the dataset."""        return self.get_profile().data['driver']    def get_img_resolution(self) -> tuple:        """Get the resolution of the dataset (rows and columns)."""        cols = self.get_profile().data['width']        rows = self.get_profile().data['height']        return rows, cols    def get_shift_parameter(self):        """Get the shift parameters of the dataset."""        gt = self.get_geo_transform()        return gt[2], gt[5]    def get_spatial_resoultion(self, in_meter=False) -> tuple:        """        Get the spatial resolution of the dataset.        :param in_meter: Whether to return the resolution in meters.        :return: The spatial resolution.        """        if in_meter:            temp_rio_ds = self.transform_to_metric_unit_projections()            return temp_rio_ds.res        return self.dataset.res    def get_unit(self) -> str:        """Get the unit of the dataset."""        crs = self.get_pyproj_crs()        return crs.to_dict()['units']    def get_radiometric_resolution(self):        """        Get the radiometric resolution of the dataset.        :return: The radiometric resolution.        """        s = self.get_profile()['dtype']        m = re.search(r'\d+$', s)        return int(m.group()) if m else None    def get_spectral_resolution(self):        """        Get the spectral resolution of the dataset.        :return: The spectral resolution.        """        return self.get_profile().data['count']    def get_geo_transform(self) -> Affine:        """        Get the affine transform of the dataset.        :return: The affine transform.            the sequence is [a,b,c,d,e,f]        """        return self.get_profile().data['transform']    def is_image_crs_same(self, raster2: 'RioRaster') -> bool:        """        Check if the CRS of two images are the same.        :param raster2: The other RioRaster object.        :return: True if the CRS are the same, False otherwise.        """        crs1 = self.get_crs()        crs2 = raster2.get_crs()        return str(crs1) == str(crs2)    def is_image_resolution_same(self, raster2: 'RioRaster') -> bool:        """        Check if the resolution of two images are the same.        :param raster2: The other RioRaster object.        :return: True if the resolution are the same, False otherwise.        """        res1 = self.get_img_resolution()        res2 = raster2.get_img_resolution()        return res1 == res2    def is_spatial_resolution_same(self, raster2: 'RioRaster', decimal_places: int = 3, tol: float = 1e-3) -> bool:        """        Check if the spatial resolution of two images are the same.        :param raster2: The other RioRaster object.        :return: True if the spatial resolution are the same, False otherwise.        """        res1 = np.round(self.get_spatial_resoultion(), decimal_places)        res2 = np.round(raster2.get_spatial_resoultion(), decimal_places)        return np.allclose(res1, res2, atol=tol)    def is_image_extent_same(self, raster2: 'RioRaster', decimal_places: int = 3, tol: float = 1e-3) -> bool:        """        Check if the extent of two images are the same, rounded to a specified number of decimal places,        and within a specified tolerance.        :param raster2: The other RioRaster object.        :param decimal_places: Number of decimal places to round to for comparison.        :param tol: The tolerance level for comparison.        :return: True if the extents are the same within the tolerance, False otherwise.        """        E1 = np.round(np.array(self.get_raster_extent()), decimal_places)        E2 = np.round(np.array(raster2.get_raster_extent()), decimal_places)        return np.allclose(E1, E2, atol=tol)    def create_ndwi_data(self, green, nir, output_path: str = None):        """        Create NDWI data from green and NIR bands.        :param green: The green band number.        :param nir: The NIR band number.        :param output_path: The output path to save the NDWI data.        :return: The NDWI data array.        """        nir_data = self.get_data_array(nir)        green_data = self.get_data_array(green)        ndwi = IndicesCalc.NDWIndices(green_data, nir_data)        ndwi = IndicesCalc.normalize(ndwi)        if output_path:            self.save_to_file(output_path, ndwi.astype(rasterio.int8))        return ndwi    def create_ndvi_data(self, red_band: int, nir_band: int, output_path: str = None):        """        Create NDVI data from red and NIR bands.        :param red_band: The red band number.        :param nir_band: The NIR band number.        :param output_path: The output path to save the NDVI data.        :return: The NDVI data array.        """        nir_data = self.get_data_array(nir_band)        red_data = self.get_data_array(red_band)        ndvi = IndicesCalc.NDVIndices(nir_data, red_data)        ndvi = IndicesCalc.normalize(ndvi)        if output_path:            self.save_to_file(output_path, ndvi.astype(rasterio.int8))        return ndvi    def vector_2_raster(self, gdv: GPDVector, value_col: str = 'id', d_type=np.uint8) -> 'RioRaster':        """        Convert a vector to raster.        :param gdv: The GeoDataFrame vector.        :param value_col: The column to use for raster values.        :param d_type: The data type of the raster.        :return: The resulting RioRaster object.        """        if str(gdv.get_crs()).lower() != str(self.get_crs()).lower():            gdv.to_crs(self.get_pyproj_crs())        shapes = gdv.get_geometry_list(value_col)        data = rasterize(shapes, out_shape=self.get_img_resolution(), transform=self.get_geo_transform())        data = data.astype(d_type)        return self.rio_raster_from_array(data)    def raster_2_vector(self, band: Union[int, np.ndarray], classes=[]) -> gpd.GeoDataFrame:        """        Convert a raster to vector.        :param band: The band number or data array to convert.        :param classes: The classes to extract.        :return: The resulting GeoDataFrame.        """        geoms = []        file_path, file_name = self.get_file_name()        if isinstance(band, np.ndarray):            band_data = band        else:            band_data = self.get_data_array(band)        c_ids = []        for vec in shapes(band_data, transform=self.get_geo_transform()):            if len(classes) == 0:                geoms.append(shape(vec[0]))                c_ids.append(vec[1])            elif vec[1] in classes:                geoms.append(shape(vec[0]))                c_ids.append(vec[1])        return gpd.GeoDataFrame({'geometry': geoms,                                 'class_id': np.array(c_ids).astype('uint16'),                                 'grid': file_name.split('.')[0]                                 }, geometry='geometry', crs=self.get_crs())    def get_tiles(self, width=64, height=64) -> 'RioRaster':        """        Get tiles of the dataset.        :param width: The width of each tile.        :param height: The height of each tile.        :return: A generator of RioRaster tiles.        """        rows, cols = self.get_img_resolution()        offsets = product(range(0, cols, width), range(0, rows, height))        big_window = windows.Window(col_off=0, row_off=0, width=cols, height=rows)        for col_off, row_off in offsets:            window = windows.Window(col_off=col_off, row_off=row_off,                                    width=width, height=height).intersection(big_window)            transform = windows.transform(window, self.get_geo_transform())            tile = self.dataset.read(window=window)            tile_raster = self.raster_from_array(tile, crs=self.get_crs(), g_transform=transform,                                                 nodata_value=self.get_nodata_value())            yield tile_raster, col_off, row_off    def get_all_tiles(self):        """        Get all tiles of the dataset.        :return: A list of tile file paths.        """        tiles = []        tile_no = 0        if self.temp_dir:            for tile_raster in self.get_tiles(width=500, height=500):                tile_no += 1                file_name = self.get_file_name()[1].split('.')[0]                tile_name = f"{self.temp_dir}/tiles/{file_name}_{tile_no}.tif"                tile_raster.save_to_file(tile_name)                tiles.append(tile_name)            return tiles        else:            da_logger.critical("Please set temp folder path first using set_temp_folder")    @staticmethod    def reverse_band_row_col(data: np.ndarray):        """        Reverse the band, row, and column order of the data array.        :param data: The data array.        :return: The reversed data array.        """        return np.moveaxis(data, 0, 2)    def save_temp_file(self, postfix: str):        """        Save the dataset as a temporary file.        :param postfix: The postfix to add to the file name.        """        if self.temp_dir:            img_name = self.get_file_name()[1].split('.')[0]            img_des = os.path.join(self.temp_dir, f"{img_name}_{postfix}.tif")            print(img_des)            self.save_to_file(img_des)        else:            da_logger.critical("Please set temp folder path first using set_temp_folder")    def resample_raster_spatial_res(self, des_res: Union[tuple, float, int], is_in_meter=False,                                    resampling_method_index=0, in_place=True):        """        Resample the raster to match the spatial resolution of a reference raster.        :param des_res: The destination raster resolution tuple(res_x, res_y).        :param resampling_method_index: The resampling method index.        :param in_place: Whether to perform the operation in place.        :return: The resampled dataset.        """        if isinstance(des_res, float) or isinstance(des_res, int):            des_res = (des_res,)        if is_in_meter and self.get_crs().is_geographic:            des_res = tuple(GeodesyOps.meter_to_dd(res) for res in des_res)        self_res = self.get_spatial_resoultion()        width = round(self.get_width() * self_res[0] / des_res[0], 0)        height = round(self.get_height() * self_res[1] / des_res[-1], 0)        return self.resample_raster(width, height, resampling_method_index, in_place)    def resample_raster(self, width, height, resampling_method_index=1, in_place=True) -> DatasetReader:        # resampling_method = [Resampling.nearest, Resampling.bilinear, Resampling.cubic, Resampling.lanczos, Resampling.average]        bands = self.dataset.count        data = self.dataset.read(            out_shape=(                bands,                int(height),                int(width)            ),            resampling=self.resampling_method[resampling_method_index]        )        geo_transform = self.dataset.transform * self.dataset.transform.scale(            (self.dataset.width / data.shape[-1]),            (self.dataset.height / data.shape[-2])        )        kwargs = self.dataset.meta.copy()        kwargs.update({            'transform': geo_transform,            'width': data.shape[-1],            'height': data.shape[-2]        })        memfile = MemoryFile()        dst = memfile.open(**kwargs)        for i in range(bands):            d = data if len(data.shape) == 2 else data[i, :, :]            dst.write(d, i + 1)        dst.close()        if in_place:            self.dataset = memfile.open()        else:            return memfile.open()    def reproject_raster(self, des_crs: pyproj.CRS = None, width=None, height=None, in_place=True,                         resampling_method_index=0):        """        Reproject the raster to a new CRS.        :param des_crs: The target CRS.        :param width: The target width.        :param height: The target height.        :param in_place: Whether to perform the operation in place.        :param resampling_method_index: The resampling method index.        :return: The reprojected dataset.        """        dst_crs = rasterio.crs.CRS.from_wkt(des_crs.to_wkt())        dst_crs = self.get_crs() if dst_crs is None else dst_crs        width = self.get_width() if width is None else width        height = self.get_height() if height is None else height        g_trans, width, height = calculate_default_transform(self.get_crs(), dst_crs, width,                                                             height, *self.get_raster_extent())        kwargs = self.get_metadata_copy()        kwargs.update({            'crs': dst_crs,            'transform': g_trans,            'width': width,            'height': height        })        memfile = MemoryFile()        dst = memfile.open(**kwargs)        for i in range(1, self.dataset.count + 1):            reproject(                source=rasterio.band(self.dataset, i),                destination=rasterio.band(dst, i),                src_transform=self.get_geo_transform(),                src_crs=self.get_crs(),                dst_transform=g_trans,                dst_crs=dst_crs,                resampling=self.resampling_method[resampling_method_index])        dst.close()        if in_place:            self.dataset = memfile.open()        else:            return memfile.open()    def clip_raster(self, aoi: Union[gpd.GeoDataFrame, shapely.geometry.Polygon, shapely.geometry.MultiPolygon],                    in_place=True, crs=0) -> 'RioRaster':        """        Clip the raster to an area of interest (AOI).        :param aoi: The area of interest.        :param in_place: Whether to perform the operation in place.        :param crs: The CRS of the AOI.        :return: The clipped RioRaster object.        """        if isinstance(aoi, shapely.geometry.Polygon) or isinstance(aoi, shapely.geometry.MultiPolygon):            aoi = gpd.GeoDataFrame(geometry=[aoi], crs=crs)        if str(aoi.crs).lower() != str(self.get_crs()).lower():            geo = aoi.to_crs(self.get_crs())        else:            geo = aoi        geom_col = GPDVector.get_geometry_column_name(geo)        geometries = [feature[geom_col] for _, feature in geo.iterrows()]        nodata = self.get_nodata_value() if self.get_nodata_value() is not None else 0        out_img, out_transform = mask(self.dataset, geometries, crop=True, nodata=nodata)        out_meta = self.dataset.meta.copy()        out_meta.update({"driver": "GTiff",                         "height": out_img.shape[1],                         "width": out_img.shape[2],                         "transform": out_transform,                         "nodata": nodata,                         "crs": self.dataset.crs})        descriptions = self.dataset.descriptions        if in_place:            self.dataset = self.rio_dataset_from_array(out_img, out_meta, descriptions)        else:            return RioRaster(self.rio_dataset_from_array(out_img, out_meta, descriptions))    def pad_raster(self, des_raster):        """        Clip or pad the raster to align with the bounds of another raster.        :param des_raster: The target RioRaster object.        """        aff: Affine = self.get_geo_transform()        des_bounds = des_raster.get_bounds()        rows, cols = rasterio.transform.rowcol(aff, xs=[des_bounds[0], des_bounds[2]],                                               ys=[des_bounds[3], des_bounds[1]])        height = rows[1] - rows[0]        width = cols[1] - cols[0]        window = windows.Window(col_off=cols[0], row_off=rows[0],                                width=width, height=height)        window_transform = windows.transform(window, self.get_geo_transform())        kwargs = self.dataset.meta.copy()        kwargs.update({            'crs': self.get_crs(),            'transform': window_transform,            'width': width,            'height': height        })        memfile = MemoryFile()        dst = memfile.open(**kwargs)        data = self.dataset.read(window=window, boundless=False, fill_value=self.dataset.nodata)        dst.write(data)        dst.close()        self.dataset = memfile.open()    def reclassify_raster(self, thresholds, band=None, nodata=0) -> 'RioRaster':        """        Reclassify the raster based on thresholds.        :param thresholds: The thresholds for reclassification.            example:  {                    "water": (('lt', 0.015), 4),                    "built-up": ((0.015, 0.02), 1),                    "barren": ((0.07, 0.27), 2),                    "vegetation": (('gt', 0.27), 3)                }        :param band: The band number to reclassify.        :param nodata: The no-data value.        :return: The reclassified data array.        """        nodata = self.get_nodata_value() if self.get_nodata_value() is not None and self.get_nodata_value() != nodata else nodata        no_of_bands = self.get_spectral_resolution()        res = []        for band_no in range(no_of_bands):            img_arr = self.get_data_array(band_no + 1)            img_arr = np.squeeze(img_arr)            classified_data = BandProcess.reclassify_band(img_arr, thresholds, nodata)            res.append(classified_data)        if no_of_bands > 0:            res = np.stack(res, axis=0)        binary_raster = self.rio_raster_from_array(res.astype(np.uint8))        return binary_raster    def make_coincident_with(self, des_raster: 'RioRaster', resampling_method_index=0):        """        Make the current raster coincident with another raster.        :param des_raster: The target RioRaster object.        :param resampling_method_index: The resampling method index.        """        # Check CRS and reproject if necessary        if not self.is_image_crs_same(des_raster):            print("Reprojecting CRS to match the target raster.")            self.reproject_raster(des_raster.get_crs(), resampling_method_index=resampling_method_index)        # Check spatial resolution and resample if necessary        if not self.is_spatial_resolution_same(des_raster):            print("Resampling spatial resolution to match the target raster.")            des_res = des_raster.get_spatial_resoultion()            self.resample_raster_spatial_res(des_res)        # Check and align extents        des_bbox = des_raster.get_envelop()        src_bbox = self.get_envelop()        if not des_bbox.equals(src_bbox):            print("Clipping dataset to the target raster extent.")            self.get_dataset_under_envelop(des_gdf=des_bbox)        # Check final resolution and resample if necessary        if not self.is_image_resolution_same(des_raster):            print("Resampling to match the target raster dimensions.")            width = des_raster.get_width()            height = des_raster.get_height()            self.resample_raster(width, height, resampling_method_index=resampling_method_index)        # Final consistency check        if not (self.is_image_crs_same(des_raster) and                self.is_spatial_resolution_same(des_raster) and                self.is_image_resolution_same(des_raster)):            raise ValueError("Failed to make the rasters coincident. Check the processing steps.")        print("Rasters are now coincident.")    def get_dataset_under_envelop(self, des_gdf: gpd.GeoDataFrame, in_place=True, pad_nodata=True) -> DatasetReader:        """        Get the dataset under an envelope, with optional padding for larger envelopes.        Args:            des_gdf: The GeoDataFrame to restrict the data.            in_place: Whether to modify the current raster object directly (True) or return a new one (False).            pad_nodata: If True, pad with nodata values when the envelope exceeds the raster's extent.        Returns:            The resulting DatasetReader, either the modified original or a new one.        """        try:            # Ensure CRS consistency            if self.get_crs().to_epsg() != des_gdf.crs.to_epsg():                des_gdf = des_gdf.to_crs(self.get_crs())            des_bounds = tuple(des_gdf.total_bounds)            print(f"Desired bounds (from envelope): {des_bounds}")            # Calculate row and column indices for the desired region            aff = self.get_geo_transform()            print(f"Geo transform: {aff}")            rows, cols = rasterio.transform.rowcol(aff, xs=[des_bounds[0], des_bounds[2]],                                                   ys=[des_bounds[3], des_bounds[1]])            # Determine width and height of the desired region            height = abs(rows[1] - rows[0])            width = abs(cols[1] - cols[0])            # Get the bounding coordinates of source            src_gdf = self.get_envelop()            src_bounds = src_gdf.total_bounds            # Calculate the amount of padding or clipping needed            pad_left = max(0, src_bounds[0] - des_bounds[0])            pad_right = max(0, des_bounds[2] - src_bounds[2])            pad_bottom = max(0, src_bounds[1] - des_bounds[1])            pad_top = max(0, des_bounds[3] - src_bounds[3])            # Adjust rows and cols for clipping or padding            if pad_left > 0:                cols = (cols[0] + pad_left, cols[1])            if pad_right > 0:                cols = (cols[0], cols[1] - pad_right)            if pad_bottom > 0:                rows = (rows[0] + pad_bottom, rows[1])            if pad_top > 0:                rows = (rows[0], rows[1] - pad_top)            # Update height and width            height = abs(rows[1] - rows[0])            width = abs(cols[1] - cols[0])            # Create the window for reading data            window = windows.Window(col_off=cols[0], row_off=rows[0], width=width, height=height)            # Read the data and handle nodata padding if needed            if pad_nodata:                fill_value = self.dataset.nodata if self.dataset.nodata is not None else 0                data = np.full((height, width), fill_value, dtype=self.dataset.dtypes[0])                read_window = windows.Window(col_off=max(0, -cols[0]), row_off=max(0, -rows[0]),                                             width=min(width, self.dataset.width),                                             height=min(height, self.dataset.height))                data[read_window.row_off:read_window.row_off + read_window.height,                read_window.col_off:read_window.col_off + read_window.width] = self.dataset.read(window=read_window,                                                                                                 boundless=True)            else:                data = self.dataset.read(window=window, boundless=True, fill_value=self.dataset.nodata)            # Create window transform            window_transform = windows.transform(window, self.get_geo_transform())            print(f"Window transform: {window_transform}")            # Create the new DatasetReader with updated metadata            kwargs = self.dataset.meta.copy()            kwargs.update({                'transform': window_transform,                'width': width,                'height': height            })            raster = self.rio_raster_from_array(data)            dataset = raster.dataset            if in_place:                self.dataset = dataset                return self.dataset            else:                return dataset        except Exception as e:            print(f"Error in get_dataset_under_envelop: {e}")            traceback.print_exc()            return None    @staticmethod    def rio_dataset_from_array(data: np.ndarray, meta, descriptions: list = None) -> DatasetReader:        """        Create a RioDataset from an array.        :param data: The data array.        :param meta: The metadata.        :param descriptions: The band descriptions.        :return: The resulting DatasetReader object.        """        bands = 1 if len(data.shape) == 2 else data.shape[0]        memfile = MemoryFile()        dst = memfile.open(**meta,                           compress='lzw',                           BIGTIFF='YES')        for i in range(bands):            d = data if len(data.shape) == 2 else data[i, :, :]            dst.write(d, i + 1)        if descriptions is not None:            dst.descriptions = descriptions        dst.close()        return memfile.open()    def change_datatype(self, new_dtype: np.dtype = "float32"):        """        Change the data type of the dataset.        :param new_dtype: The new data type.        """        data = self.get_data_array()        out_meta = self.dataset.meta.copy()        out_meta.update({"nodata": self.get_nodata_value(),                         "dtype": new_dtype})        self.dataset = self.rio_dataset_from_array(data, out_meta)    def add_nodata_value(self, val):        """        Add a no-data value to the dataset.        :param val: The no-data value to add.        """        out_meta = self.dataset.meta.copy()        out_meta.update({"nodata": val})        data = self.get_data_array()        self.dataset = self.rio_dataset_from_array(data, out_meta)    def get_x_y_value_raster(self, in_lat_long=False) -> (np.ndarray, np.ndarray):        """        Get the X and Y raster values.        :param in_lat_long: Whether to return values in latitude and longitude.        :return: The X and Y raster values.        """        rows, cols = self.get_img_resolution()        if in_lat_long and self.get_raster_srid() != 4326:            geo_t, width, height = calculate_default_transform(self.get_crs(), CRS.from_epsg(4326),                                                               self.get_width(), self.get_height(),                                                               *self.get_raster_extent())        else:            geo_t = self.get_geo_transform()        X = np.zeros((rows, cols))        Y = np.zeros((rows, cols))        for i in np.arange(cols):            for j in np.arange(i, rows):                Y[j, :] = i * geo_t[3] + j * geo_t[4] + geo_t[5]                break            X[:, i] = i * geo_t[0] + j * geo_t[1] + geo_t[2]        return X, Y    def calculate_spatial_resolution_in_meter(self):        """        Calculate the spatial resolution in meters.        :return: The horizontal and vertical distances between each pixel in meters.        """        geo_out = self.get_geo_transform()        size_Y, size_X = self.get_img_resolution()        lon = np.arange(size_X + 1) * geo_out[0] + geo_out[2] - 0.5 * geo_out[0]        lat = np.arange(size_Y + 1) * geo_out[4] + geo_out[5] - 0.5 * geo_out[4]        dlat_2d = np.array([lat, ] * int(np.size(lon, 0))).transpose()        dlon_2d = np.array([lon, ] * int(np.size(lat, 0)))        R_earth = 6371000        lonRad = dlon_2d * np.pi / 180        latRad = dlat_2d * np.pi / 180        lonRad_dif = abs(lonRad[:, 1:] - lonRad[:, :-1])        latRad_dif = abs(latRad[:-1] - latRad[1:])        a = np.sin(latRad_dif[:, :-1] / 2) * np.sin(latRad_dif[:, :-1] / 2)        clat = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))        dlat = R_earth * clat        b = np.cos(latRad[1:, :-1]) * np.cos(latRad[:-1, :-1]) * np.sin(lonRad_dif[:-1, :] / 2) * np.sin(            lonRad_dif[:-1, :] / 2)        clon = 2 * np.arctan2(np.sqrt(b), np.sqrt(1 - b))        dlon = R_earth * clon        return dlon, dlat    def transform_to_metric_unit_projections(self, in_place=False):        """        Transform the dataset to a metric unit projection.        :param in_place: Whether to perform the operation in place.        :return: The transformed dataset.        """        if self.get_pyproj_crs().to_epsg() == 4326:            gt = self.get_geo_transform()            utm_srid = GeodesyOps.utm_srid_from_coord(gt[2], gt[5])            temp_rio_ds = self.reproject_raster(CRS.from_epsg(utm_srid), in_place=False)        else:            temp_rio_ds = self.get_dataset()        if in_place:            self.dataset = temp_rio_ds        else:            return temp_rio_ds    def get_pixel_value(self, x: float, y: float):        """        Get the pixel value at a specific location.        :param x: The X coordinate.        :param y: The Y coordinate.        :return: The pixel values for all bands at the specified location.        """        row, col = self.dataset.index(x, y)        values = []        for band in range(1, self.dataset.count + 1):            data = self.dataset.read(band)            values.append(data[row, col])        return values    def get_pixel_area_band(self):        """        Get the pixel area band of the dataset.        :return: The pixel area band.        """        temp_rio_ds = self.transform_to_metric_unit_projections()        cols = temp_rio_ds.profile.data['width']        rows = temp_rio_ds.profile.data['height']        geo = temp_rio_ds.profile.data['transform']        return np.ones((rows, cols)) * geo[0] * geo[4]    @staticmethod    def get_s3_session(aws_access_key_id, aws_secret_access_key, region_name):        """        Get an AWS S3 session.        :param aws_access_key_id: The AWS access key ID.        :param aws_secret_access_key: The AWS secret access key.        :param region_name: The AWS region name.        :return: The AWS session.        """        return Session(aws_access_key_id, aws_secret_access_key, region_name)    def upload_to_s3(self, img_des: str, session: Session):        """        Upload the dataset to an S3 bucket.        :param img_des: The destination path in the S3 bucket.        :param session: The AWS session.        """        self.write_to_file(img_des, self.get_data_array(), self.get_crs(),                           self.get_geo_transform(), self.get_nodata_value(), session)    def get_band_name(self, band_no: int):        """        Get the name of a band.        :param band_no: The band number.        :return: The band name.        """        if self.dataset.descriptions and len(self.dataset.descriptions) >= band_no:            return self.dataset.descriptions[band_no]    def get_band_summaries(self) -> pd.DataFrame:        """        Get summaries of all bands in the dataset.        :return: A DataFrame containing the summaries.        """        summaries = {}        for i in range(self.get_spectral_resolution()):            band_name = self.get_band_name(i)            data = self.get_data_array(i)            no_data = self.get_nodata_value()            summary = BandProcess.get_summary_data(data, nodata=no_data)            summaries[band_name] = summary        return pd.DataFrame(summaries).T    def get_raster_aoi(self, band_number: int, mask_value: float = None) -> gpd.GeoDataFrame:        """        Extract polygons from a specific band of a raster file that are not 'no data' or a specific mask value.        :param band_number: The band number to process.        :param mask_value: Value to mask out. If None, use the 'no data' value of the band.        :return: List of Shapely polygons.        """        polygons = []        band = self.get_data_array(band_number)        if mask_value is None:            mask_value = self.get_nodata_value_of_band(band_number)        binary_mask = np.where((band != mask_value) & (~np.isnan(band)), 1, 0)        shapes_and_values = shapes(binary_mask.astype(np.uint8), transform=self.get_geo_transform())        polygons = [shape(geom) for geom, value in shapes_and_values if value == 1 and not shape(geom).is_empty]        return gpd.GeoDataFrame(geometry=polygons, crs=self.get_crs())