Metadata-Version: 2.1
Name: IM_GBO_optimizer
Version: 2.0.0
Summary: A Mathematical-Based Optimization Method
Author-email: Iman Ahmadianfar <im.ahmadian@gmail.com>
License: MIT License
        
        Copyright (c) 2024 Iman Ahmadianfar
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to deal
        in the Software without restriction, including without limitation the rights
        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
        copies of the Software, and to permit persons to whom the Software is
        furnished to do so, subject to the following conditions:
        
        The above copyright notice and this permission notice shall be included in all
        copies or substantial portions of the Software.
        
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
Project-URL: Homepage, https://www.mathworks.com/matlabcentral/profile/authors/13490648
Project-URL: Bug Tracker, https://github.com/ImanAhm
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE

# Gradient_Based-Optimizatio-in-Python
This repository contains the implementation of a novel metaheuristic optimization algorithm, the Gradient-Based Optimizer (GBO). Inspired by the gradient-based Newton’s method, GBO is designed for both mathematical optimization and real-world problem-solving with enhanced exploration and exploitation capabilities.

# Gradient-Based Optimizer (GBO)  

This repository contains the implementation of a novel metaheuristic optimization algorithm, the Gradient-Based Optimizer (GBO). Inspired by the gradient-based Newton’s method, GBO is designed for both mathematical optimization and real-world problem-solving with enhanced exploration and exploitation capabilities.  

## Overview  

The Gradient-Based Optimizer (GBO) employs two primary operators:  

1. **Gradient Search Rule (GSR)**: Uses the gradient-based method to bolster the exploration capability and hasten convergence, allowing the algorithm to find better positions in the search space.  
   
2. **Local Escaping Operator (LEO)**: Facilitates the escape from local optima, enhancing the ability of GBO to avoid becoming trapped and thus enabling more thorough exploration of the search space.  

## Key Features  

- **Robust Exploration & Exploitation**: Effectively balances exploration and exploitation of the search space, driven by advanced operators.  
- **Convergence Enhancement**: Accelerates convergence rate while maintaining solution diversity to avoid local optima.  
- **Versatile Application**: Demonstrates efficacy across mathematical test functions and complex engineering problems.  
- **Comparative Performance**: Outperforms existing algorithms in literature, offering superior solutions in benchmark tests.  

## Implementation Details  

This Python implementation utilizes the `numpy` library for efficient numerical computations and matrix operations. The main function `GBO` can be customized to suit specific optimization problems.  

## Installation 
- **pip install IM_GBO_optimizer**

## Prerequisites  

- Python (>=3.6)  
- NumPy  

## Usage  

The GBO can be applied to a variety of optimization problems, requiring only the definition of an objective function and problem-specific parameters. Here’s how to get started:  

```python  
from IM_GBO_optimizer import GBO  # Assuming the file is named gbo.py  

def sample_objective_function(x):  
    return sum(x**2)  # Example objective function  

result = GBO(  
    nP=30,                # Number of population members  
    MaxIt=100,            # Maximum number of iterations  
    lb=-10,               # Lower bound of search space  
    ub=10,                # Upper bound of search space  
    dim=5,                # Dimensionality  
    fobj=sample_objective_function,  
    constraint_handling="clip",  
    verbose=True  
)  

print("Best Solution:", result.bestIndividual)  
print("Best Cost:", result.BestCost)

## Parameters
nP: Population size

MaxIt: Maximum number of iterations.

lb: Lower bound for each dimension.

ub: Upper bound for each dimension.

dim: Problem dimensionality.

fobj: Objective function to minimize.

constraint_handling: Method for handling constraints ("clip" or "RI").

verbose: When True, displays iteration progress.

## Output
The GBO function returns an object capturing:


The GBO algorithm was rigorously tested:

Phase 1: 28 mathematical functions assessed the algorithm's characteristics against five existing algorithms, showing superior performance.
Phase 2: Applied to six engineering problems, further demonstrating its efficacy in real-world applications.
License
This project is released under the MIT License.

Acknowledgments
Recognition of the algorithm's design principles inspired by the gradient method, and efforts taken to tailor the GBO for both broad and specialized applications.
